{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stackbacker/Langchain-work/blob/main/Multimodal_RAG_with_GPT_4o_and_Pathway.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qZiRz8TyH2Tp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Hands-on Multimodal RAG with GPT-4o and Pathway**"
      ],
      "metadata": {
        "id": "-k-SGriV9WOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSERT PHOTO HERE"
      ],
      "metadata": {
        "id": "8iSl32znaqD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multimodal Retrieval-Augmented Generation (MM-RAG)** systems are transforming the way we enhance Language Models and Generative AI. By incorporating a variety of data types within one application, these systems significantly expand their capabilities and applications.\n",
        "\n",
        "While traditional [RAG systems](https://pathway.com/blog/retrieval-augmented-generation-beginners-guide-rag-apps) primarily use and parse text, Multimodal RAG systems integrate multimedia elements such as images, audio, and video. This integration is beneficial even for use cases that might initially seem like pure text scenarios, such as handling charts, data, and information stored as images.\n",
        "\n",
        "By the end of this hands-on guide, you will:\n",
        "\n",
        "Have a concise understanding of Multimodal RAG systems\n",
        "Appreciate the enhanced retrieval and generation capabilities offered by multimodal search and RAG, especially in contexts involving financial data and complex visual elements.\n",
        "See an app template that can be replicated enabling you to build a multimodal RAG application using production-ready open source frameworks such as Pathway."
      ],
      "metadata": {
        "id": "YQbScd7hUSrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Legacy Retrieval Augmented Generation (RAG)\n",
        "A Retrieval-Augmented Generation (RAG) system enhances Language Models by fetching relevant information from external data sources that aren't part of the model's training data. This retrieved context is then incorporated into the user prompt, helping the model generate more accurate and contextually informed responses without the need for extensive retraining. RAG systems are particularly useful in addressing issues such as:\n",
        "- **Privacy for Enterprise Use-Cases**: Ensuring sensitive information is kept secure, in a Faraday Cage.\n",
        "- **High accuracy**: Reducing the LLM application’s tendency to generate incorrect information by 90% or more.\n",
        "- **Verifiability of Information**: Providing references to verify the generated content.\n",
        "- **Lower Compute Costs**: Reducing the need for frequent retraining.\n",
        "- **Scalability**: Easily updating and expanding the model’s knowledge base.\n"
      ],
      "metadata": {
        "id": "aBWjMKRa-qm6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# How is Multimodal RAG Different?\n",
        "\n",
        "Traditional RAG systems are limited to text-based data since most LLMs understand only text, leading to less coherent outputs when images or text stored as images are involved. This is now changing.\n",
        "New generative models, both closed and open source, can understand text and images. With these advancements, multimodal RAG systems can retrieve and process multimedia data, such as images, audio, and video, alongside text. By integrating multimodal search and retrieval with LLMs, we achieve more coherent outputs, especially for complex queries requiring diverse information formats. This approach significantly enhances performance, as demonstrated in the example below.\n"
      ],
      "metadata": {
        "id": "ubIaksxa-saB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSERT PHOTO 2 HERE"
      ],
      "metadata": {
        "id": "c8iM-Gx7az4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why is Multimodal Search and RAG Useful?\n",
        "\n",
        "Multimodal search and RAG allows systems to access and interpret diverse data types, leading to richer and more accurate responses. For instance:\n",
        "- **Visual Data**: Tables, charts, and diagrams, especially in critical use cases like financial documents, can be efficiently interpreted using models like GPT-4o. This enhances the accuracy of generative AI applications. An example of the same can be seen in this [popular example](https://github.com/pathwaycom/llm-app/blob/7e6a32985a3932daf71178230220993553a5e893/examples/pipelines/gpt_4o_multimodal_rag/src/_parser_utils.py#L116) or below in this guide, where visual data is parsed as images to improve understanding and searchability.\n",
        "- **Indexing**: The explained content from tables is saved with the document chunk into the index, making it easily searchable and more useful for specific queries. This ensures that diverse data types are readily accessible, enhancing the system's performance and utility.\n",
        "- **Multimodal In-Context Learning**: Modern multimodal RAG systems are capable of in-context learning. For example, they can generate images from demonstrations, meaning you can feed the model demonstration images and text so it generates new images that follow the visual characteristics of these in-context examples. This capability further broadens the applications and effectiveness of multimodal RAG systems.\n"
      ],
      "metadata": {
        "id": "SQEtbmAc-vIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Architecture Used for Multimodal RAG for Production Use Cases\n",
        "\n",
        "Building a multimodal RAG system for production requires a robust and scalable architecture that can handle diverse data types and ensure seamless integration and retrieval of context. This architecture must efficiently manage data ingestion, processing, and querying, while providing accurate and timely responses to user queries. Key components include data parsers, vector databases, LLMs, and real-time data synchronization tools.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CzxFvo4S_RIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specific Architecture for This Guide\n",
        "\n",
        "Building a multimodal RAG system for production requires a robust and scalable architecture capable of handling diverse data types, ensuring seamless integration, and providing accurate responses. Key components include data parsers, vector databases, LLMs, and real-time data synchronization tools."
      ],
      "metadata": {
        "id": "QqRKtQsjXdsY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INSERT PHOTO 3 HERE"
      ],
      "metadata": {
        "id": "kWZ9muLYa6fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leveraging Pathway for Multimodal Search and RAG\n",
        "\n",
        "Pathway enhances this architecture by providing real-time data synchronization, secure document handling, and a built-in vector store. Pathway’s enterprise connectors enable incremental synchronization with platforms like Sharepoint and Google Drive. This allows us to perform live document indexing, ensuring efficient and secure data management."
      ],
      "metadata": {
        "id": "rSCN_FUTXek_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key Components of the Multimodal RAG Architecture\n",
        "\n",
        "- **BaseRAGQuestionAnswerer Class**: Integrates foundational RAG components.\n",
        "- **GPT-4o by Open AI**: Used for extracting and understanding multimodal data, generating vector embeddings, and for answering queries with retrieved context.\n",
        "- **Pathway**: Provides real-time synchronization, secure document handling, and a robust in-memory vector store for indexing.\n",
        "\n",
        "This architecture ensures our multimodal RAG system is efficient, scalable, and capable of handling complex data types, making it ideal for production use cases, especially in finance where understanding data within PDFs is crucial.\n"
      ],
      "metadata": {
        "id": "znH7QGu2-6qz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step by Step Guide for Multimodal RAG**"
      ],
      "metadata": {
        "id": "ptCZWfEz_cnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finance Use Case: Understanding Data within PDFs**\n",
        "\n",
        "In this guide, we focus on a popular finance use case: **understanding data within PDFs**. Financial documents often contain **complex tables** and **charts** that require precise interpretation. We’ve seen examples where you can do this with open source models, having the entire multimodal RAG pipeline within a Faraday cage so **data stays within your ecosystem**.\n",
        "\n",
        "However, here we use Open AI’s popular Multimodal LLM, [**GPT-4o**](https://openai.com/index/hello-gpt-4o/). It’s used at two key stages:\n",
        "1. **Parsing Process**: Tables are extracted as images, and GPT-4o then explains the content of these tables in detail. The explained content is saved with the document chunk into the index for easy searchability.\n",
        "   \n",
        "2. **Answering Questions**: Questions are sent to the LLM with the relevant context, including parsed tables. This allows the generation of accurate responses based on the comprehensive multimodal context.\n",
        "\n"
      ],
      "metadata": {
        "id": "Wnn4c0-5VGmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Install Required Libraries**\n",
        "\n",
        "In this cell, we install all the necessary libraries required for the project. These libraries include:\n",
        "\n",
        "- **pathway[xpack-llm]>=0.11.0**: Provides tools for building and deploying LLM applications.\n",
        "- **openparse==0.5.6**: Library for parsing various document formats including PDFs.\n",
        "- **python-dotenv==1.0.1**: Manages environment variables from a `.env` file.\n",
        "- **unstructured[all-docs]==0.10.28**: A library for working with unstructured document formats.\n",
        "- **mpmath==1.3.0**: A library for arbitrary-precision arithmetic.\n",
        "- **pydantic**: Data validation and settings management using Python type annotations.\n",
        "- **pypdf**: A library for working with PDF documents.\n",
        "- **Pillow**: The Python Imaging Library for opening, manipulating, and saving many different image file formats.\n"
      ],
      "metadata": {
        "id": "5rHNeRXI8t2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU-HG5_4_Lza",
        "outputId": "feeeee65-8c96-439d-84fa-320d797e9a1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.8.0 requires sqlglot<=20.11,>=20.8.0, but you have sqlglot 10.6.1 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\n",
            "ibis-framework 8.0.0 requires sqlglot<=20.11,>=18.12.0, but you have sqlglot 10.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pathway[xpack-llm]>=0.11.0 openparse==0.5.6 python-dotenv==1.0.1 unstructured[all-docs]==0.10.28 mpmath==1.3.0 pydantic pypdf Pillow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Set Up OpenAI API Key**\n",
        "\n",
        "In this cell, we set the OpenAI API key as an environment variable. Replace the placeholder with your actual API key.\n"
      ],
      "metadata": {
        "id": "dp6GwenS80Po"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jSPFNMNVCIC0"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"Paste your OpenAI API key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QFE-c0iuvo5G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set the OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ULGb2_As2Eq"
      },
      "source": [
        "##**Document parsers:**\n",
        "\n",
        "Functions that take raw bytes and return a list of text\n",
        "chunks along with their metadata."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Import Necessary Libraries**\n",
        "\n",
        "This cell imports the required libraries and modules for custom document parsing and related functionalities. It also sets up logging and initializes the OpenAIChat for language model interactions.\n"
      ],
      "metadata": {
        "id": "J2qndG_s9Urg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "4FzQWBSAlw3H",
        "outputId": "bd2c702e-00a3-48dc-a54e-85038438879b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
              "  var reloading = false;\n",
              "  var Bokeh = root.Bokeh;\n",
              "\n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
              "        if (callback != null)\n",
              "          callback();\n",
              "      });\n",
              "    } finally {\n",
              "      delete root._bokeh_onload_callbacks;\n",
              "    }\n",
              "    console.debug(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
              "    if (css_urls == null) css_urls = [];\n",
              "    if (js_urls == null) js_urls = [];\n",
              "    if (js_modules == null) js_modules = [];\n",
              "    if (js_exports == null) js_exports = {};\n",
              "\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    if (!reloading) {\n",
              "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    }\n",
              "\n",
              "    function on_load() {\n",
              "      root._bokeh_is_loading--;\n",
              "      if (root._bokeh_is_loading === 0) {\n",
              "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
              "        run_callbacks()\n",
              "      }\n",
              "    }\n",
              "    window._bokeh_on_load = on_load\n",
              "\n",
              "    function on_error() {\n",
              "      console.error(\"failed to load \" + url);\n",
              "    }\n",
              "\n",
              "    var skip = [];\n",
              "    if (window.requirejs) {\n",
              "      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
              "      require([\"tabulator\"], function(Tabulator) {\n",
              "\twindow.Tabulator = Tabulator\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"moment\"], function(moment) {\n",
              "\twindow.moment = moment\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel\"], function(jsPanel) {\n",
              "\twindow.jsPanel = jsPanel\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-modal\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-tooltip\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-hint\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-layout\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-contextmenu\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"jspanel-dock\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"gridstack\"], function(GridStack) {\n",
              "\twindow.GridStack = GridStack\n",
              "\ton_load()\n",
              "      })\n",
              "      require([\"notyf\"], function() {\n",
              "\ton_load()\n",
              "      })\n",
              "      root._bokeh_is_loading = css_urls.length + 11;\n",
              "    } else {\n",
              "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
              "    }\n",
              "\n",
              "    var existing_stylesheets = []\n",
              "    var links = document.getElementsByTagName('link')\n",
              "    for (var i = 0; i < links.length; i++) {\n",
              "      var link = links[i]\n",
              "      if (link.href != null) {\n",
              "\texisting_stylesheets.push(link.href)\n",
              "      }\n",
              "    }\n",
              "    for (var i = 0; i < css_urls.length; i++) {\n",
              "      var url = css_urls[i];\n",
              "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
              "\ton_load()\n",
              "\tcontinue;\n",
              "      }\n",
              "      const element = document.createElement(\"link\");\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.rel = \"stylesheet\";\n",
              "      element.type = \"text/css\";\n",
              "      element.href = url;\n",
              "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
              "      document.body.appendChild(element);\n",
              "    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
              "      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
              "      for (var i = 0; i < urls.length; i++) {\n",
              "        skip.push(urls[i])\n",
              "      }\n",
              "    }    var existing_scripts = []\n",
              "    var scripts = document.getElementsByTagName('script')\n",
              "    for (var i = 0; i < scripts.length; i++) {\n",
              "      var script = scripts[i]\n",
              "      if (script.src != null) {\n",
              "\texisting_scripts.push(script.src)\n",
              "      }\n",
              "    }\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
              "\tif (!window.requirejs) {\n",
              "\t  on_load();\n",
              "\t}\n",
              "\tcontinue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (var i = 0; i < js_modules.length; i++) {\n",
              "      var url = js_modules[i];\n",
              "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
              "\tif (!window.requirejs) {\n",
              "\t  on_load();\n",
              "\t}\n",
              "\tcontinue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onload = on_load;\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.src = url;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    for (const name in js_exports) {\n",
              "      var url = js_exports[name];\n",
              "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
              "\tif (!window.requirejs) {\n",
              "\t  on_load();\n",
              "\t}\n",
              "\tcontinue;\n",
              "      }\n",
              "      var element = document.createElement('script');\n",
              "      element.onerror = on_error;\n",
              "      element.async = false;\n",
              "      element.type = \"module\";\n",
              "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      element.textContent = `\n",
              "      import ${name} from \"${url}\"\n",
              "      window.${name} = ${name}\n",
              "      window._bokeh_on_load()\n",
              "      `\n",
              "      document.head.appendChild(element);\n",
              "    }\n",
              "    if (!js_urls.length && !js_modules.length) {\n",
              "      on_load()\n",
              "    }\n",
              "  };\n",
              "\n",
              "  function inject_raw_css(css) {\n",
              "    const element = document.createElement(\"style\");\n",
              "    element.appendChild(document.createTextNode(css));\n",
              "    document.body.appendChild(element);\n",
              "  }\n",
              "\n",
              "  var js_urls = [\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n",
              "  var js_modules = [];\n",
              "  var js_exports = {};\n",
              "  var css_urls = [\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n",
              "  var inline_js = [    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "function(Bokeh) {} // ensure no trailing comma for IE\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "\ttry {\n",
              "          inline_js[i].call(root, root.Bokeh);\n",
              "\t} catch(e) {\n",
              "\t  if (!reloading) {\n",
              "\t    throw e;\n",
              "\t  }\n",
              "\t}\n",
              "      }\n",
              "      // Cache old bokeh versions\n",
              "      if (Bokeh != undefined && !reloading) {\n",
              "\tvar NewBokeh = root.Bokeh;\n",
              "\tif (Bokeh.versions === undefined) {\n",
              "\t  Bokeh.versions = new Map();\n",
              "\t}\n",
              "\tif (NewBokeh.version !== Bokeh.version) {\n",
              "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
              "\t}\n",
              "\troot.Bokeh = Bokeh;\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    }\n",
              "    root._bokeh_is_initializing = false\n",
              "  }\n",
              "\n",
              "  function load_or_wait() {\n",
              "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
              "    // versions of Bokeh and its dependencies at the same time.\n",
              "    // In recent versions we use the root._bokeh_is_initializing flag\n",
              "    // to determine whether there is an ongoing attempt to initialize\n",
              "    // bokeh, however for backward compatibility we also try to ensure\n",
              "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
              "    // before older versions are fully initialized.\n",
              "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
              "      root._bokeh_is_initializing = false;\n",
              "      root._bokeh_onload_callbacks = undefined;\n",
              "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
              "      load_or_wait();\n",
              "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
              "      setTimeout(load_or_wait, 100);\n",
              "    } else {\n",
              "      root._bokeh_is_initializing = true\n",
              "      root._bokeh_onload_callbacks = []\n",
              "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
              "      if (!reloading && !bokeh_loaded) {\n",
              "\troot.Bokeh = undefined;\n",
              "      }\n",
              "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
              "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "\trun_inline_js();\n",
              "      });\n",
              "    }\n",
              "  }\n",
              "  // Give older versions of the autoload script a head-start to ensure\n",
              "  // they initialize before we start loading newer version.\n",
              "  setTimeout(load_or_wait, 100)\n",
              "}(window));"
            ],
            "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.4'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'tabulator': 'https://cdn.jsdelivr.net/npm/tabulator-tables@5.5.0/dist/js/tabulator.min', 'moment': 'https://cdn.jsdelivr.net/npm/luxon/build/global/luxon.min', 'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"tabulator\"], function(Tabulator) {\n\twindow.Tabulator = Tabulator\n\ton_load()\n      })\n      require([\"moment\"], function(moment) {\n\twindow.moment = moment\n\ton_load()\n      })\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 11;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['Tabulator'] !== undefined) && (!(window['Tabulator'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['moment'] !== undefined) && (!(window['moment'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/luxon/build/global/luxon.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.8/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.8/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/js/tabulator.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/luxon/build/global/luxon.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.4.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.4.min.js\", \"https://cdn.holoviz.org/panel/1.3.8/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [\"https://cdn.holoviz.org/panel/1.3.8/dist/bundled/datatabulator/tabulator-tables@5.5.0/dist/css/tabulator_simple.min.css\"];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
            "application/javascript": [
              "\n",
              "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
              "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
              "}\n",
              "\n",
              "\n",
              "    function JupyterCommManager() {\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
              "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        comm_manager.register_target(comm_id, function(comm) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        });\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        });\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
              "          var messages = comm.messages[Symbol.asyncIterator]();\n",
              "          function processIteratorResult(result) {\n",
              "            var message = result.value;\n",
              "            console.log(message)\n",
              "            var content = {data: message.data, comm_id};\n",
              "            var buffers = []\n",
              "            for (var buffer of message.buffers || []) {\n",
              "              buffers.push(new DataView(buffer))\n",
              "            }\n",
              "            var metadata = message.metadata || {};\n",
              "            var msg = {content, buffers, metadata}\n",
              "            msg_handler(msg);\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "          return messages.next().then(processIteratorResult);\n",
              "        })\n",
              "      }\n",
              "    }\n",
              "\n",
              "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
              "      if (comm_id in window.PyViz.comms) {\n",
              "        return window.PyViz.comms[comm_id];\n",
              "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
              "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
              "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
              "        if (msg_handler) {\n",
              "          comm.on_msg(msg_handler);\n",
              "        }\n",
              "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
              "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
              "        comm.open();\n",
              "        if (msg_handler) {\n",
              "          comm.onMsg = msg_handler;\n",
              "        }\n",
              "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
              "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
              "        comm_promise.then((comm) => {\n",
              "          window.PyViz.comms[comm_id] = comm;\n",
              "          if (msg_handler) {\n",
              "            var messages = comm.messages[Symbol.asyncIterator]();\n",
              "            function processIteratorResult(result) {\n",
              "              var message = result.value;\n",
              "              var content = {data: message.data};\n",
              "              var metadata = message.metadata || {comm_id};\n",
              "              var msg = {content, metadata}\n",
              "              msg_handler(msg);\n",
              "              return messages.next().then(processIteratorResult);\n",
              "            }\n",
              "            return messages.next().then(processIteratorResult);\n",
              "          }\n",
              "        }) \n",
              "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
              "          return comm_promise.then((comm) => {\n",
              "            comm.send(data, metadata, buffers, disposeOnDone);\n",
              "          });\n",
              "        };\n",
              "        var comm = {\n",
              "          send: sendClosure\n",
              "        };\n",
              "      }\n",
              "      window.PyViz.comms[comm_id] = comm;\n",
              "      return comm;\n",
              "    }\n",
              "    window.PyViz.comm_manager = new JupyterCommManager();\n",
              "    \n",
              "\n",
              "\n",
              "var JS_MIME_TYPE = 'application/javascript';\n",
              "var HTML_MIME_TYPE = 'text/html';\n",
              "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
              "var CLASS_NAME = 'output';\n",
              "\n",
              "/**\n",
              " * Render data to the DOM node\n",
              " */\n",
              "function render(props, node) {\n",
              "  var div = document.createElement(\"div\");\n",
              "  var script = document.createElement(\"script\");\n",
              "  node.appendChild(div);\n",
              "  node.appendChild(script);\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when a new output is added\n",
              " */\n",
              "function handle_add_output(event, handle) {\n",
              "  var output_area = handle.output_area;\n",
              "  var output = handle.output;\n",
              "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "    return\n",
              "  }\n",
              "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "  if (id !== undefined) {\n",
              "    var nchildren = toinsert.length;\n",
              "    var html_node = toinsert[nchildren-1].children[0];\n",
              "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var scripts = [];\n",
              "    var nodelist = html_node.querySelectorAll(\"script\");\n",
              "    for (var i in nodelist) {\n",
              "      if (nodelist.hasOwnProperty(i)) {\n",
              "        scripts.push(nodelist[i])\n",
              "      }\n",
              "    }\n",
              "\n",
              "    scripts.forEach( function (oldScript) {\n",
              "      var newScript = document.createElement(\"script\");\n",
              "      var attrs = [];\n",
              "      var nodemap = oldScript.attributes;\n",
              "      for (var j in nodemap) {\n",
              "        if (nodemap.hasOwnProperty(j)) {\n",
              "          attrs.push(nodemap[j])\n",
              "        }\n",
              "      }\n",
              "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
              "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
              "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
              "    });\n",
              "    if (JS_MIME_TYPE in output.data) {\n",
              "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
              "    }\n",
              "    output_area._hv_plot_id = id;\n",
              "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
              "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
              "    } else {\n",
              "      window.PyViz.plot_index[id] = null;\n",
              "    }\n",
              "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "    var bk_div = document.createElement(\"div\");\n",
              "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "    var script_attrs = bk_div.children[0].attributes;\n",
              "    for (var i = 0; i < script_attrs.length; i++) {\n",
              "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "    }\n",
              "    // store reference to server id on output_area\n",
              "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle when an output is cleared or removed\n",
              " */\n",
              "function handle_clear_output(event, handle) {\n",
              "  var id = handle.cell.output_area._hv_plot_id;\n",
              "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
              "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
              "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
              "  if (server_id !== null) {\n",
              "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
              "    return;\n",
              "  } else if (comm !== null) {\n",
              "    comm.send({event_type: 'delete', 'id': id});\n",
              "  }\n",
              "  delete PyViz.plot_index[id];\n",
              "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
              "    var doc = window.Bokeh.index[id].model.document\n",
              "    doc.clear();\n",
              "    const i = window.Bokeh.documents.indexOf(doc);\n",
              "    if (i > -1) {\n",
              "      window.Bokeh.documents.splice(i, 1);\n",
              "    }\n",
              "  }\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle kernel restart event\n",
              " */\n",
              "function handle_kernel_cleanup(event, handle) {\n",
              "  delete PyViz.comms[\"hv-extension-comm\"];\n",
              "  window.PyViz.plot_index = {}\n",
              "}\n",
              "\n",
              "/**\n",
              " * Handle update_display_data messages\n",
              " */\n",
              "function handle_update_output(event, handle) {\n",
              "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
              "  handle_add_output(event, handle)\n",
              "}\n",
              "\n",
              "function register_renderer(events, OutputArea) {\n",
              "  function append_mime(data, metadata, element) {\n",
              "    // create a DOM node to render to\n",
              "    var toinsert = this.create_output_subarea(\n",
              "    metadata,\n",
              "    CLASS_NAME,\n",
              "    EXEC_MIME_TYPE\n",
              "    );\n",
              "    this.keyboard_manager.register_events(toinsert);\n",
              "    // Render to node\n",
              "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "    render(props, toinsert[0]);\n",
              "    element.append(toinsert);\n",
              "    return toinsert\n",
              "  }\n",
              "\n",
              "  events.on('output_added.OutputArea', handle_add_output);\n",
              "  events.on('output_updated.OutputArea', handle_update_output);\n",
              "  events.on('clear_output.CodeCell', handle_clear_output);\n",
              "  events.on('delete.Cell', handle_clear_output);\n",
              "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
              "\n",
              "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "    safe: true,\n",
              "    index: 0\n",
              "  });\n",
              "}\n",
              "\n",
              "if (window.Jupyter !== undefined) {\n",
              "  try {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  } catch(err) {\n",
              "  }\n",
              "}\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>*[data-root-id],\n",
              "*[data-root-id] > * {\n",
              "  box-sizing: border-box;\n",
              "  font-family: var(--jp-ui-font-family);\n",
              "  font-size: var(--jp-ui-font-size1);\n",
              "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
              "}\n",
              "\n",
              "/* Override VSCode background color */\n",
              ".cell-output-ipywidget-background:has(\n",
              "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
              "  ),\n",
              ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
              "  background-color: transparent !important;\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='159e4a19-6e52-403d-a49f-81c570e7a14b'>\n",
              "  <div id=\"e29d701f-543a-42c2-9783-3aa99164dd0c\" data-root-id=\"159e4a19-6e52-403d-a49f-81c570e7a14b\" style=\"display: contents;\"></div>\n",
              "</div>\n",
              "<script type=\"application/javascript\">(function(root) {\n",
              "  var docs_json = {\"cde8b693-ce37-4172-a411-edef47503519\":{\"version\":\"3.3.4\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"159e4a19-6e52-403d-a49f-81c570e7a14b\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"648cbcc9-4145-4cad-9a60-e28391555ca0\",\"attributes\":{\"plot_id\":\"159e4a19-6e52-403d-a49f-81c570e7a14b\",\"comm_id\":\"c668af25de864057b920382492e12fc4\",\"client_comm_id\":\"e86ee2c81cb4437c9a31dc8a02be50c5\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
              "  var render_items = [{\"docid\":\"cde8b693-ce37-4172-a411-edef47503519\",\"roots\":{\"159e4a19-6e52-403d-a49f-81c570e7a14b\":\"e29d701f-543a-42c2-9783-3aa99164dd0c\"},\"root_ids\":[\"159e4a19-6e52-403d-a49f-81c570e7a14b\"]}];\n",
              "  var docs = Object.values(docs_json)\n",
              "  if (!docs) {\n",
              "    return\n",
              "  }\n",
              "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
              "  function embed_document(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "    for (const render_item of render_items) {\n",
              "      for (const root_id of render_item.root_ids) {\n",
              "\tconst id_el = document.getElementById(root_id)\n",
              "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
              "\t  const root_el = id_el.children[0]\n",
              "\t  root_el.id = root_el.id + '-rendered'\n",
              "\t}\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  function get_bokeh(root) {\n",
              "    if (root.Bokeh === undefined) {\n",
              "      return null\n",
              "    } else if (root.Bokeh.version !== py_version) {\n",
              "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
              "\treturn null\n",
              "      }\n",
              "      return root.Bokeh.versions.get(py_version);\n",
              "    } else if (root.Bokeh.version === py_version) {\n",
              "      return root.Bokeh\n",
              "    }\n",
              "    return null\n",
              "  }\n",
              "  function is_loaded(root) {\n",
              "    var Bokeh = get_bokeh(root)\n",
              "    return (Bokeh != null && Bokeh.Panel !== undefined && ( root['Tabulator'] !== undefined) && ( root['Tabulator'] !== undefined))\n",
              "  }\n",
              "  if (is_loaded(root)) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (is_loaded(root)) {\n",
              "        clearInterval(timer);\n",
              "        embed_document(root);\n",
              "      } else if (document.readyState == \"complete\") {\n",
              "        attempts++;\n",
              "        if (attempts > 200) {\n",
              "          clearInterval(timer);\n",
              "\t  var Bokeh = get_bokeh(root)\n",
              "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
              "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
              "\t  } else {\n",
              "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
              "\t    embed_document(root)\n",
              "\t  }\n",
              "        }\n",
              "      }\n",
              "    }, 25, root)\n",
              "  }\n",
              "})(window);</script>"
            ],
            "application/vnd.holoviews_exec.v0+json": ""
          },
          "metadata": {
            "application/vnd.holoviews_exec.v0+json": {
              "id": "159e4a19-6e52-403d-a49f-81c570e7a14b"
            }
          }
        }
      ],
      "source": [
        "# Imports for the custom document parser and related functionality\n",
        "import asyncio\n",
        "import base64\n",
        "import concurrent.futures\n",
        "import io\n",
        "import logging\n",
        "from typing import List, Literal, Union\n",
        "\n",
        "import PIL\n",
        "from openparse.pdf import Pdf\n",
        "from openparse import DocumentParser, consts, tables, text\n",
        "from openparse.schemas import ParsedDocument, TableElement\n",
        "from openparse.tables.parse import (\n",
        "    Bbox,\n",
        "    PyMuPDFArgs,\n",
        "    TableTransformersArgs,\n",
        "    UnitableArgs, _ingest_with_pymupdf,\n",
        "    _ingest_with_table_transformers,\n",
        "    _ingest_with_unitable,\n",
        ")\n",
        "\n",
        "from openparse.tables.utils import adjust_bbox_with_padding, crop_img_with_padding\n",
        "from pathway.internals import udfs\n",
        "from pathway.xpacks.llm._utils import _coerce_sync\n",
        "from pathway.xpacks.llm.llms import OpenAIChat\n",
        "from pydantic import BaseModel,ConfigDict, Field"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lgdlbkNX9WTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Default Table Parse Prompt**\n",
        "\n",
        "We define the default prompt that will be used for parsing tables from images. This prompt instructs the language model to explain the table in JSON format, ensuring no details are skipped.\n",
        "\n"
      ],
      "metadata": {
        "id": "91OACifn-UFw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Qum-Uhv0mUL2"
      },
      "outputs": [],
      "source": [
        "# Define default prompt for table parsing\n",
        "DEFAULT_TABLE_PARSE_PROMPT = \"\"\"Explain the given table in JSON format in detail.\n",
        "Do not skip over details or units/metrics.\n",
        "Make sure column and row names are understandable.\n",
        "If it is not a table, return 'No table.' .\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Logging Configuration**\n",
        "\n",
        "Configure logging settings if needed. This helps in debugging and monitoring the code execution."
      ],
      "metadata": {
        "id": "210lXao5A59A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure logging if needed\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format=\"%(asctime)s %(name)s %(levelname)s %(message)s\",\n",
        "#     datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "# )\n",
        "\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "J1SVYiPNA4kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**LLM Table Parsing Function**\n",
        "\n",
        "Define the function `llm_parse_table` that uses OpenAIChat to parse a table from a base64-encoded image. The function sends the image and prompt to the language model and returns the parsed table content."
      ],
      "metadata": {
        "id": "jHPOsfSAA4QN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_parse_table(\n",
        "    image, model=\"gpt-4o\", prompt=DEFAULT_TABLE_PARSE_PROMPT, **kwargs\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Use OpenAIChat to parse a table image encoded as base64.\n",
        "\n",
        "    Args:\n",
        "    - image: Base64-encoded image string.\n",
        "    - model: LLM model to use (default: \"gpt-4o\").\n",
        "    - prompt: Prompt for the language model (default: DEFAULT_TABLE_PARSE_PROMPT).\n",
        "    - kwargs: Additional keyword arguments.\n",
        "\n",
        "    Returns:\n",
        "    - str: Parsed table content as a string.\n",
        "    \"\"\"\n",
        "    content = [\n",
        "        {\"type\": \"text\", \"text\": prompt},\n",
        "        {\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image}\"},\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": content}]\n",
        "\n",
        "    logger.info(f\"Parsing table, model: {model}\\nmessages: {str(content)[:350]}...\")\n",
        "\n",
        "    # Use _coerce_sync to run llm_parse_table synchronously\n",
        "    response = _coerce_sync(chat.__wrapped__)(model=model, messages=messages, **kwargs)\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "ly82IvMTBp5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###**LLMArgs Class**\n",
        "\n",
        "Define the `LLMArgs` class using Pydantic. This class models the arguments needed for LLM table parsing, including the parsing algorithm, minimum table confidence, LLM model, and prompt."
      ],
      "metadata": {
        "id": "Jx1MRFk9CHW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMArgs(BaseModel):\n",
        "    \"\"\"\n",
        "    Pydantic model for LLM parsing arguments.\n",
        "    \"\"\"\n",
        "    parsing_algorithm: Literal[\"llm\"] = Field(default=\"llm\")\n",
        "    min_table_confidence: float = Field(default=0.9, ge=0.0, le=1.0)\n",
        "    llm_model: str = Field(default=\"gpt-4o\")\n",
        "    prompt: str = Field(default=DEFAULT_TABLE_PARSE_PROMPT)\n",
        "\n",
        "    model_config = ConfigDict(extra=\"forbid\")"
      ],
      "metadata": {
        "id": "euByS2HgBuv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " ### **Convert Args Dictionary to Model**\n",
        "\n",
        "Define the function `_table_args_dict_to_model` which converts a dictionary of table parsing arguments to the appropriate model based on the parsing algorithm specified."
      ],
      "metadata": {
        "id": "VaRfcYTSCKKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _table_args_dict_to_model(args_dict: dict):\n",
        "    \"\"\"\n",
        "    Convert a dictionary of table parsing arguments to the appropriate model.\n",
        "\n",
        "    Args:\n",
        "    - args_dict: Dictionary of table parsing arguments.\n",
        "\n",
        "    Returns:\n",
        "    - Union[TableTransformersArgs, PyMuPDFArgs, UnitableArgs, LLMArgs]: Parsed table arguments as a model.\n",
        "    \"\"\"\n",
        "    if args_dict[\"parsing_algorithm\"] == \"table-transformers\":\n",
        "        return TableTransformersArgs(**args_dict)\n",
        "    elif args_dict[\"parsing_algorithm\"] == \"pymupdf\":\n",
        "        return PyMuPDFArgs(**args_dict)\n",
        "    elif args_dict[\"parsing_algorithm\"] == \"unitable\":\n",
        "        return UnitableArgs(**args_dict)\n",
        "    elif args_dict[\"parsing_algorithm\"] == \"llm\":\n",
        "        return LLMArgs(**args_dict)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Unsupported parsing_algorithm: {args_dict['parsing_algorithm']}\"\n",
        "        )\n"
      ],
      "metadata": {
        "id": "svELK-E0Bxr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "###**Convert Image to Base64**\n",
        "\n",
        "Define the function `img_to_b64` which converts a PIL image to a base64-encoded string. This is used for sending images to the language model."
      ],
      "metadata": {
        "id": "CxSVmhpPCMvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def img_to_b64(img: PIL.Image) -> str:\n",
        "    \"\"\"\n",
        "    Convert a PIL image to a base64-encoded string.\n",
        "\n",
        "    Args:\n",
        "    - img: PIL Image object.\n",
        "\n",
        "    Returns:\n",
        "    - str: Base64-encoded image string.\n",
        "    \"\"\"\n",
        "    buffer = io.BytesIO()\n",
        "    img.save(buffer, format=\"PNG\")\n",
        "    buffer.seek(0)\n",
        "\n",
        "    img_bytes = buffer.read()\n",
        "\n",
        "    return base64.b64encode(img_bytes).decode(\"utf-8\")\n"
      ],
      "metadata": {
        "id": "VSw_gY-BB0gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ingest Tables with LLM**\n",
        "\n",
        "Define the function `_ingest_with_llm` which uses the language model to ingest and parse tables from a PDF document. The function converts PDF pages to images, detects table bounding boxes, crops the table images, and sends them to the language model for parsing."
      ],
      "metadata": {
        "id": "9yeKEJ_TCOtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _ingest_with_llm(\n",
        "    doc: Pdf,\n",
        "    args: LLMArgs,\n",
        "    verbose: bool = False,\n",
        ") -> List[TableElement]:\n",
        "    try:\n",
        "        from openparse.tables.table_transformers.ml import find_table_bboxes\n",
        "        from openparse.tables.utils import doc_to_imgs\n",
        "\n",
        "    except ImportError as e:\n",
        "        raise ImportError(\n",
        "            \"Table detection and extraction requires the `torch`, `torchvision` and `transformers` libraries to be installed.\",  # noqa: E501\n",
        "            e,\n",
        "        )\n",
        "    pdoc = doc.to_pymupdf_doc()\n",
        "    pdf_as_imgs = doc_to_imgs(pdoc)\n",
        "\n",
        "    pages_with_tables = {}\n",
        "    for page_num, img in enumerate(pdf_as_imgs):\n",
        "        pages_with_tables[page_num] = find_table_bboxes(img, args.min_table_confidence)\n",
        "\n",
        "    tables = []\n",
        "    image_ls = []\n",
        "    for page_num, table_bboxes in pages_with_tables.items():\n",
        "        page = pdoc[page_num]\n",
        "        for table_bbox in table_bboxes:\n",
        "            padding_pct = 0.05\n",
        "            padded_bbox = adjust_bbox_with_padding(\n",
        "                bbox=table_bbox.bbox,\n",
        "                page_width=page.rect.width,\n",
        "                page_height=page.rect.height,\n",
        "                padding_pct=padding_pct,\n",
        "            )\n",
        "            table_img = crop_img_with_padding(pdf_as_imgs[page_num], padded_bbox)\n",
        "\n",
        "            img = img_to_b64(table_img)\n",
        "\n",
        "            image_ls.append(img)\n",
        "\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        task_results = list(\n",
        "            executor.map(\n",
        "                lambda img: llm_parse_table(img, args.llm_model, args.prompt),\n",
        "                image_ls,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    for table_str in task_results:\n",
        "        fy0 = page.rect.height - padded_bbox[3]\n",
        "        fy1 = page.rect.height - padded_bbox[1]\n",
        "\n",
        "        table_elem = TableElement(\n",
        "            bbox=Bbox(\n",
        "                page=page_num,\n",
        "                x0=padded_bbox[0],\n",
        "                y0=fy0,\n",
        "                x1=padded_bbox[2],\n",
        "                y1=fy1,\n",
        "                page_width=page.rect.width,\n",
        "                page_height=page.rect.height,\n",
        "            ),\n",
        "            text=table_str,\n",
        "        )\n",
        "\n",
        "        tables.append(table_elem)\n",
        "\n",
        "    return tables"
      ],
      "metadata": {
        "id": "zcwWdAhKB4in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ingest Function**\n",
        "\n",
        "Define the main `ingest` function which decides which table parsing method to use based on the provided arguments. It supports various parsing algorithms including `table-transformers`, `pymupdf`, `unitable`, and `llm`."
      ],
      "metadata": {
        "id": "d-quGNunCRHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ingest(\n",
        "    doc: Pdf,\n",
        "    parsing_args: Union[\n",
        "        TableTransformersArgs, PyMuPDFArgs, UnitableArgs, LLMArgs, None\n",
        "    ] = None,\n",
        "    verbose: bool = False,\n",
        ") -> List[TableElement]:\n",
        "    if isinstance(parsing_args, TableTransformersArgs):\n",
        "        return _ingest_with_table_transformers(doc, parsing_args, verbose)\n",
        "    elif isinstance(parsing_args, PyMuPDFArgs):\n",
        "        return _ingest_with_pymupdf(doc, parsing_args, verbose)\n",
        "    elif isinstance(parsing_args, UnitableArgs):\n",
        "        return _ingest_with_unitable(doc, parsing_args, verbose)\n",
        "    elif isinstance(parsing_args, LLMArgs):\n",
        "        return _ingest_with_llm(doc, parsing_args, verbose)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported parsing_algorithm.\")\n"
      ],
      "metadata": {
        "id": "iS71AAzVB80I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Custom Document Parser Class**\n",
        "\n",
        "Define the `CustomDocumentParser` class which extends the base `DocumentParser` class. This custom parser uses the language model to parse tables from documents. The `parse` method combines text and table parsing results into a single parsed document.\n"
      ],
      "metadata": {
        "id": "5lBH0YXiCbyi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "51lbpA5ZqNnJ"
      },
      "outputs": [],
      "source": [
        "class CustomDocumentParser(DocumentParser):\n",
        "    \"\"\"\n",
        "    Custom document parser using multi-modal LLM.\n",
        "\n",
        "    Uses pymupdf to parse the document and runs LLM on table images.\n",
        "\n",
        "    Args:\n",
        "    - DocumentParser: Base class for document parsing.\n",
        "\n",
        "    Methods:\n",
        "    - parse(doc): Parse a given document with multi-modal LLM.\n",
        "    \"\"\"\n",
        "\n",
        "    def parse(self, doc) -> ParsedDocument:\n",
        "        \"\"\"\n",
        "        Parse a given document with multi-modal LLM.\n",
        "\n",
        "        Args:\n",
        "        - doc: Document to be parsed.\n",
        "\n",
        "        Returns:\n",
        "        - ParsedDocument: Parsed document containing nodes and metadata.\n",
        "        \"\"\"\n",
        "        text_engine = \"pymupdf\"\n",
        "        text_elems = text.ingest(doc, parsing_method=text_engine)\n",
        "        text_nodes = self._elems_to_nodes(text_elems)\n",
        "\n",
        "        table_nodes = []\n",
        "        table_args_obj = None\n",
        "        if self.table_args:\n",
        "            table_args_obj = _table_args_dict_to_model(self.table_args)\n",
        "            table_elems = ingest(doc, table_args_obj, verbose=self._verbose)\n",
        "            table_nodes = self._elems_to_nodes(table_elems)\n",
        "\n",
        "        nodes = text_nodes + table_nodes\n",
        "        nodes = self.processing_pipeline.run(nodes)\n",
        "\n",
        "        parsed_doc = ParsedDocument(\n",
        "            nodes=nodes,\n",
        "            filename=\"Path(file).name\",\n",
        "            num_pages=doc.num_pages,\n",
        "            coordinate_system=consts.COORDINATE_SYSTEM,\n",
        "            table_parsing_kwargs=(\n",
        "                table_args_obj.model_dump() if table_args_obj else None\n",
        "            ),\n",
        "            creation_date=doc.file_metadata.get(\"creation_date\"),\n",
        "            last_modified_date=doc.file_metadata.get(\"last_modified_date\"),\n",
        "            last_accessed_date=doc.file_metadata.get(\"last_accessed_date\"),\n",
        "            file_size=doc.file_metadata.get(\"file_size\"),\n",
        "        )\n",
        "        return parsed_doc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **OpenParse Class**\n",
        "\n",
        "The `OpenParse` class is defined here, extending the `pw.UDF` class. This class uses the `open-parse` library to parse documents. The parsing algorithm can be specified through the `table_args` dictionary, allowing the use of different algorithms like `llm`, `unitable`, `pymupdf`, and `table-transformers`.\n",
        "\n",
        "### Arguments:\n",
        "- **table_args**: A dictionary containing the table parser arguments. By default, it uses the `llm` algorithm.\n",
        "- **cache_strategy**: Defines the caching mechanism. If provided, it should be a valid `CacheStrategy` object to enable caching.\n",
        "\n",
        "\n",
        "### **Document Parsing Method**\n",
        "\n",
        "The `__wrapped__` method of the `OpenParse` class handles the core functionality of parsing the document. It reads the contents of a PDF file, uses the `CustomDocumentParser` to parse the document, and returns the parsed content as a list of tuples containing the text and metadata.\n",
        "\n",
        "### Steps:\n",
        "1. **Read the PDF file** using `PdfReader`.\n",
        "2. **Parse the document** using `CustomDocumentParser`.\n",
        "3. **Extract nodes** from the parsed content.\n",
        "4. **Log the number of nodes** parsed.\n",
        "5. **Return the parsed documents** as a list of tuples with text and metadata."
      ],
      "metadata": {
        "id": "yi31ZiSBDq8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "x5DpNdsqP2yp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import logging\n",
        "from io import BytesIO\n",
        "\n",
        "import pathway as pw\n",
        "from pathway.internals import udfs\n",
        "from pathway.optional_import import optional_imports\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class OpenParse(pw.UDF):\n",
        "    \"\"\"\n",
        "    Parse document using `https://github.com/Filimoa/open-parse <https://github.com/Filimoa/open-parse>`_.\n",
        "\n",
        "    `parsing_algorithm` can be one of `llm`, `unitable`, `pymupdf`, `table-transformers`.\n",
        "    While using in the VectorStoreServer, splitter can be set to `None` as OpenParse already chunks the documents.\n",
        "\n",
        "\n",
        "    Args:\n",
        "        - table_args: dict containing the table parser arguments.\n",
        "        - cache_strategy: Defines the caching mechanism. To enable caching,\n",
        "            a valid `CacheStrategy` should be provided.\n",
        "            See `Cache strategy <https://pathway.com/developers/api-docs/udfs#pathway.udfs.CacheStrategy>`_\n",
        "            for more information. Defaults to None.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        table_args: dict = {\"parsing_algorithm\": \"llm\"},\n",
        "        cache_strategy: udfs.CacheStrategy | None = None,\n",
        "    ):\n",
        "        with optional_imports(\"xpack-llm\"):\n",
        "            import openparse  # noqa:F401\n",
        "            from pypdf import PdfReader  # noqa:F401\n",
        "\n",
        "            # from ._parser_utils import CustomDocumentParser\n",
        "\n",
        "        super().__init__(cache_strategy=cache_strategy)\n",
        "\n",
        "        self.doc_parser = CustomDocumentParser(table_args=table_args)\n",
        "\n",
        "        self.kwargs = dict(table_args=table_args)\n",
        "\n",
        "    def __wrapped__(self, contents: bytes) -> list[tuple[str, dict]]:\n",
        "        import openparse\n",
        "        from pypdf import PdfReader\n",
        "\n",
        "        reader = PdfReader(stream=BytesIO(contents))\n",
        "        doc = openparse.Pdf(file=reader)\n",
        "\n",
        "        parsed_content = self.doc_parser.parse(doc)\n",
        "        nodes = [i for i in parsed_content.nodes]\n",
        "\n",
        "        logger.info(\n",
        "            f\"OpenParser completed parsing, total number of nodes: {len(nodes)}\"\n",
        "        )\n",
        "\n",
        "        metadata: dict = {}\n",
        "        docs = list(map(lambda x: (x.dict()[\"text\"], metadata), nodes))\n",
        "\n",
        "        return docs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iGdygT2uYQ1"
      },
      "source": [
        "##**Document Processing and Question Answering Setup:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create Data Directory**\n",
        "\n",
        "Create a 'data' directory if it doesn't already exist. This is where the uploaded files will be stored.\n",
        "Then upload your pdf document\n"
      ],
      "metadata": {
        "id": "ublsBY0GFAbk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RAacHMGtP6uI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "f3ac3bf6-7037-4b1d-f0cf-145043b38fe3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5ff9de0b-e0e7-440f-b689-241659a23209\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5ff9de0b-e0e7-440f-b689-241659a23209\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 20230203_alphabet_10K.pdf to 20230203_alphabet_10K.pdf\n"
          ]
        }
      ],
      "source": [
        "# Create the 'data' folder if it doesn't exist\n",
        "!mkdir -p data\n",
        "\n",
        "# Upload a file directly into the 'data' folder\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    import shutil\n",
        "    shutil.move(filename, f'./data/{filename}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import Necessary Modules**\n",
        "\n",
        "Import additional necessary modules, set up the environment variable for Tesseract, and configure logging settings.\n"
      ],
      "metadata": {
        "id": "er_e08YxFJQg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Do_eyVjtRERO"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "\n",
        "os.environ[\"TESSDATA_PREFIX\"] = \"/usr/share/tesseract/tessdata/\"\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import pathway as pw\n",
        "from pathway.udfs import DiskCache, ExponentialBackoffRetryStrategy\n",
        "from pathway.xpacks.llm import embedders, llms, prompts\n",
        "from pathway.xpacks.llm.question_answering import BaseRAGQuestionAnswerer\n",
        "from pathway.xpacks.llm.vector_store import VectorStoreServer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_NSNHuJOFSC4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7JkgVurETD13"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"%(asctime)s %(name)s %(levelname)s %(message)s\",\n",
        "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Read Document**\n",
        "\n",
        "Read the document from the data folder. This cell assumes that the uploaded file is a sample document in the 'data' folder.\n"
      ],
      "metadata": {
        "id": "D7HFGv7ZFl_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "C6EcAshZWP8F"
      },
      "outputs": [],
      "source": [
        "path = \"./data/\"\n",
        "\n",
        "# Assuming 'sample_document.txt' was uploaded\n",
        "# Read the document from the data folder\n",
        "folder = pw.io.fs.read(\n",
        "    path=path,\n",
        "    format=\"binary\",\n",
        "    with_metadata=True,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Check If your file has been read**"
      ],
      "metadata": {
        "id": "vW93IAzCFnWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj1Pr3wSudRz",
        "outputId": "ad2142ab-c98b-4cce-cbe7-084aa6a4bd3b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20230203_alphabet_10K.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0dfjSuGyegCh"
      },
      "outputs": [],
      "source": [
        "sources = [\n",
        "    folder,\n",
        "]\n",
        "\n",
        "chat = llms.OpenAIChat(\n",
        "    model=\"gpt-4o\",\n",
        "    retry_strategy=ExponentialBackoffRetryStrategy(max_retries=6),\n",
        "    cache_strategy=DiskCache(),\n",
        "    temperature=0.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNkAW9DUepaL",
        "outputId": "682ff8ba-54fa-4aef-dd15-8e3b1424b874"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cell 4: Pathway components configured.\n"
          ]
        }
      ],
      "source": [
        "parser = OpenParse()\n",
        "embedder = embedders.OpenAIEmbedder(cache_strategy=DiskCache())\n",
        "\n",
        "doc_store = VectorStoreServer(\n",
        "    *sources,\n",
        "    embedder=embedder,\n",
        "    splitter=None,  # OpenParse parser handles the chunking\n",
        "    parser=parser,\n",
        ")\n",
        "\n",
        "print(\"Cell 4: Pathway components configured.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KRQDWWmtJeaV"
      },
      "outputs": [],
      "source": [
        "app = BaseRAGQuestionAnswerer(\n",
        "        llm=chat,\n",
        "        indexer=doc_store,\n",
        "        search_topk=6,\n",
        "        short_prompt_template=prompts.prompt_qa,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Configure and Run Question Answering Server**\n",
        "\n",
        "Configure and run the question answering server using `BaseRAGQuestionAnswerer`. This server listens on port 8000 and processes incoming queries.\n"
      ],
      "metadata": {
        "id": "63WRqIkRF3k5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dr9mhBk0O92n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ffe6073-e21f-4fdb-bb2b-be9a4bf93ec9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/beartype/_util/hint/pep/utilpeptest.py:311: BeartypeDecorHintPep585DeprecationWarning: PEP 484 type hint typing.Sequence[str] deprecated by PEP 585. This hint is scheduled for removal in the first Python version released after October 5th, 2025. To resolve this, import this hint from \"beartype.typing\" rather than \"typing\". For further commentary and alternatives, see also:\n",
            "    https://beartype.readthedocs.io/en/latest/api_roar/#pep-585-deprecations\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "app.build_server(host=\"0.0.0.0\", port=8000)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# app.run_server()"
      ],
      "metadata": {
        "id": "mC__32oHtcod"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "moBoS74LO-gD"
      },
      "outputs": [],
      "source": [
        "import threading"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = threading.Thread(target=app.run_server, name=\"BaseRAGQuestionAnswerer\")\n",
        "t.daemon = True\n",
        "thr = t.start()"
      ],
      "metadata": {
        "id": "IVAv4CvIspUh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**List Documents**\n",
        "\n",
        "List documents processed by the server using the `requests` library. This is an alternative to using the curl command.\n"
      ],
      "metadata": {
        "id": "RhkXzt5cGBW4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X 'POST'   'http://0.0.0.0:8000/v1/pw_list_documents'   -H 'accept: */*'   -H 'Content-Type: application/json'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3q4qwCPttWG0",
        "outputId": "8c3e3fbc-dafd-4507-9cd0-e6b9375e9b19"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{\"created_at\": 1718873636, \"modified_at\": 1718873636, \"owner\": \"root\", \"path\": \"data/20230203_alphabet_10K.pdf\", \"seen_at\": 1718873664}]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://0.0.0.0:8000/v1/pw_list_documents\"\n",
        "headers = {\n",
        "    \"accept\": \"*/*\",\n",
        "    \"Content-Type\": \"application/json\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, headers=headers)"
      ],
      "metadata": {
        "id": "eD1qE6_It6Os"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P0AHgKMt8lV",
        "outputId": "a0625834-d29d-45f8-d9e4-79233852a572"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'created_at': 1718873636,\n",
              "  'modified_at': 1718873636,\n",
              "  'owner': 'root',\n",
              "  'path': 'data/20230203_alphabet_10K.pdf',\n",
              "  'seen_at': 1718873664}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ask Questions and Get answers**\n",
        "\n",
        "Query the server to get answers from the documents. This cell sends a prompt to the server and receives the response.\n",
        "\n",
        "Make changes to the prompt and ask questions to get information from your documents"
      ],
      "metadata": {
        "id": "BYNQh0JPGKBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X 'POST'   'http://0.0.0.0:8000/v1/pw_ai_answer'   -H 'accept: */*'   -H 'Content-Type: application/json'   -d '{\"prompt\": \"How much was Operating lease cost in 2021?`\"}'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjsA8X0ayRUk",
        "outputId": "49d382ba-8cd6-447e-a681-b2d346807d42"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"$2,699 million\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xwed75kJGrvY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**\n",
        "\n",
        "This showcase demonstrates the setup of a robust Retrieval-Augmented Generation (RAG) pipeline using GPT-4o and Pathway, specifically tailored for processing financial reports and tables. By integrating advanced natural language processing with multimodal capabilities, this solution enhances accuracy and usability in handling complex document structures.\n",
        "\n",
        "### **Key Highlights:**\n",
        "- **Advanced Table Parsing**: Utilizing GPT-4o to extract and understand table data from PDFs, improving accuracy in answering queries based on financial information.\n",
        "  \n",
        "- **Dynamic Document Synchronization**: The pipeline automatically updates document indices as files are added or modified, ensuring real-time access to the latest data.\n",
        "\n",
        "- **Comparative Advantage**: Demonstrates superior performance over traditional RAG approaches, particularly in handling table-based queries with precision.\n",
        "\n",
        "### **Architecture Overview:**\n",
        "The architecture leverages Pathway's modules, including document parsers, LLMs, and indexing strategies, orchestrated via the BaseRAGQuestionAnswerer class. This setup supports seamless integration and efficient query handling.\n",
        "\n",
        "### **Next Steps:**\n",
        "Explore advanced features such as re-ranking for query prioritization and hybrid indexing for enhanced retrieval efficiency.\n",
        "Customize your RAG application with tailored document processing and UI design to optimize user interaction.\n",
        "\n",
        "###Ready to start building?\n",
        "Check out a range of easy to use [app templates](https://pathway.com/developers/showcases), and begin building amazing Multimodal RAG apps with the completely free community version of Pathway.\n",
        "\n",
        "### Learn More:\n",
        "- [Pathway Documentation](https://pathway.com/)\n",
        "\n"
      ],
      "metadata": {
        "id": "0LW4j1RE6NN0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}